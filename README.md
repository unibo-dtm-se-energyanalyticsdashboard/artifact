# ğŸ§  Energy Analytics Dashboard

A modular Python project for data ingestion, transformation, and visualization of European energy data using **Poetry**, **Dash**, and **GitHub Actions**.

---

## ğŸš€ Overview

This project follows a clean and extensible architecture designed for automation, reproducibility, and deployment.
It integrates with **ENTSO-E APIs**, ingests energy data into a **PostgreSQL database**, and provides an interactive **Dash dashboard** for analytics and visualization.

---

## âš™ï¸ Main Features

* Modular ETL (Extractâ€“Transformâ€“Load) pipeline
* Database connection and schema initialization (PostgreSQL)
* Automatic orchestration of ingestion tasks
* Interactive Dash-based dashboard for analytics
* Continuous Integration and Deployment via GitHub Actions
* Dependency management with Poetry
* Automated versioning and dependency updates

---

## ğŸ§© Project Structure

```text
.
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ check.yml           # Course-like CI: pip install, syntax check, mypy (tolerant), unit tests, coverage upload
â”‚   â”œâ”€â”€ ci.yml              # Minimal CI (single Python on ubuntu): syntax & tests
â”‚   â””â”€â”€ deploy.yml          # Optional release workflow (kept from template; can be wired to semantic-release later)
â”‚
â”œâ”€â”€ artifact/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ db_init.sh      # Helper: apply SQL schema to the configured PostgreSQL database
â”‚   â”‚   â””â”€â”€ ingest.py       # CLI entrypoint for ETL (modes: full_2025 | last_10_days; countries e.g., FR DE)
â”‚   â””â”€â”€ sql/
â”‚       â””â”€â”€ 01_schema.sql   # DDL: countries, energy_production, energy_consumption, cross_border_flow (+ constraints)
â”‚
â”œâ”€â”€ src/edas/
â”‚   â”œâ”€â”€ __init__.py         # Package marker
â”‚   â”œâ”€â”€ config.py           # Loads settings from env (.env): DB_* and ENTSOE_API_KEY
â”‚   â”œâ”€â”€ pipeline.py         # Orchestrates ETL: computes time windows, calls fetchers, and upserts rows
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ connection.py   # SQLAlchemy engine builder (reads DB config from env)
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ entsoe_client.py # ENTSO-E queries (consumption, generation mix, cross-border flows) + timezone handling
â”‚   â”‚   â””â”€â”€ upsert.py        # Bulk upsert functions for the three fact tables
â”‚   â”‚
â”‚   â””â”€â”€ dashboard/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ queries.py      # SQL/aggregation helpers used by the dashboard
â”‚       â””â”€â”€ app.py          # Dash UI: KPIs header + tabs (Time Series, Production Mix, Flows, Heatmap, Tables)
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_smoke.py       # Minimal smoke test (kept to satisfy CI)
â”‚
â”œâ”€â”€ .env                    # Local secrets/config (NOT committed) â€“ you create this from the example
â”œâ”€â”€ .env.example            # Safe example of required variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CHANGELOG.md            # Generated/updated during releases (if you enable semantic-release)
â”œâ”€â”€ LICENSE                 # Apache-2.0 (as in template)
â”œâ”€â”€ poetry.toml             # Poetry configuration (virtualenvs.in-project = true recommended)
â”œâ”€â”€ pyproject.toml          # Project metadata + Poetry dependencies & scripts
â”œâ”€â”€ poetry.lock             # Locked dependency graph (generated by poetry install)
â”œâ”€â”€ renovate.json           # Renovate configuration (dependency updates)
â”œâ”€â”€ requirements.txt        # Used by CI to bootstrap Poetry (or basic pip installs, depending on workflow)
â””â”€â”€ release.config.mjs      # Semantic-release config (kept from template; optional in this project)
```

---

## ğŸ§° Setup Instructions

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
poetry install
```

### 2ï¸âƒ£ Initialize the database

```bash
bash artifact/scripts/db_init.sh
```

### 3ï¸âƒ£ Run ingestion (fetch & store data)

```bash
python artifact/scripts/ingest.py
```

### 4ï¸âƒ£ Launch the dashboard

```bash
poetry run python -m src.edas.dashboard.app
```

Then open [http://127.0.0.1:8050](http://127.0.0.1:8050) in your browser.

---

## ğŸ§ª Testing

Unit and smoke tests are automatically run by **GitHub Actions** for each commit and pull request.
You can run them locally via:

```bash
poetry run python -m unittest discover -v
```

---

## ğŸ” CI/CD Integration

* **`check.yml`** â†’ Runs syntax, linting, and unit tests
* **`ci.yml`** â†’ Minimal CI workflow on Ubuntu
* **`deploy.yml`** â†’ Optional automated release on PyPI (using semantic-release)

---

## ğŸ“¦ Versioning & Releases

Semantic versioning is handled automatically through commit messages following [Conventional Commits](https://www.conventionalcommits.org/).
New releases are published to **PyPI** whenever changes are merged into the `main` branch.

---

## ğŸ“œ License

Distributed under the **Apache License 2.0**.
See [`LICENSE`](LICENSE) for more details.
